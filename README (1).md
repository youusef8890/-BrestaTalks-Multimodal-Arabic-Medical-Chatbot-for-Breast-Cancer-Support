# ğŸ©º BrestaTalks â€“ Multimodal Arabic Medical Chatbot for Breast Cancer Support

**BrestaTalks** is an advanced multimodal medical chatbot built to support Arabic-speaking users through their breast cancer journey. It combines **Natural Language Processing (NLP)**, **Visual Question Answering (VQA)**, **voice input**, and **machine translation**, enabling users to interact using **text, images, and voice** â€” all in Arabic.

ğŸ§  Think of it as **ChatGPT for breast cancer** that understands and explains Arabic medical questions and medical images like mammograms â€” with multilingual model integration for real-world impact.

---

## ğŸš€ Key Features

- ğŸ—£ï¸ **Arabic Language Support** â€“ Right-to-left layout, proper localization, and medical terminology  
- ğŸ’¬ **Text + Voice Chat** â€“ Users can ask medical questions via text or Arabic speech input  
- ğŸ–¼ï¸ **Medical Image Understanding (VQA)** â€“ Ask questions about uploaded images (e.g., mammograms)  
- ğŸŒ **Translation Layer** â€“ Arabicâ†”English pipeline for medical image Q&A  
- ğŸ¤– **AI-Powered Answers** â€“ Using powerful open-source LLMs and visual models  
- ğŸ§˜â€â™€ï¸ **Emotional Support** â€“ Compassionate and culturally-aware chatbot responses  
- ğŸ“± **Mobile-Friendly** â€“ Fully responsive UI with dark mode support  
- â˜ï¸ **Cloud Ready** â€“ Frontend deployed on Vercel, backend prepared for cloud/NGROK  

---

## ğŸ§  Underlying AI Models

| Input Type | Task                       | Model Used                            |
|------------|----------------------------|----------------------------------------|
| ğŸ“ Text     | Arabic Q&A                 | Aya LLM (Arabic medical model)         |
| ğŸ”Š Voice    | Speech-to-Text             | Whisper (for Arabic voice recognition) |
| ğŸ“Š Embedding| Semantic Search / Retrieval| multilingual-e5-large                  |
| ğŸ–¼ï¸ Image    | Visual Q&A                 | MedGEMMA                               |
| ğŸŒ Translation | English â†” Arabic        | Helsinki-NLP/opus-mt-en-ar + inverse   |

---

## ğŸ§¬ How It Works

1. **User Input**: Message sent via text, voice, or image  
2. **Frontend (Next.js)**: Captures, validates, and prepares input with Arabic support  
3. **Backend (FastAPI)**:
   - Uses **Aya** for Arabic medical Q&A  
   - Uses **MedGEMMA + Helsinki** for VQA with translation layer  
   - Uses **Whisper** for voice input processing  
   - Uses **multilingual-e5-large** for semantic search (e.g., dataset grounding)  
4. **Output**: Arabic response returned and rendered in UI with proper RTL formatting

---

## ğŸŒ Stack Overview

| Layer    | Technology                            |
|----------|----------------------------------------|
| Frontend | Next.js 15, Tailwind CSS, TypeScript   |
| Backend  | FastAPI (Python), RESTful APIs         |
| AI Models| Aya, MedGEMMA, Whisper, multilingual-e5, Helsinki-NLP |
| Deploy   | Vercel (Frontend), Ngrok / Cloud-ready (Backend) |

---

## âœ… System Highlights

- ğŸ”“ Custom user authentication and profile management  
- ğŸ“² Mobile-first responsive chat interface  
- ğŸŒ Arabic NLP with real-time voice and text support  
- ğŸ§  VQA with medical image understanding and translation  
- ğŸ’¬ Live chat experience with loading states, quick replies, and history  

---

## ğŸ“ Project Pages

```
/pages
  /chat       - Main multimodal chat interface
  /auth/*     - Login, register, forgot password
  /profile    - User account and preferences
  /about      - Project goals and context
  /contact    - Support & feedback
/api/chat     - Core API endpoint
```

---

## ğŸ§ª Example Interaction

**ğŸ¤– You are BRESTA TALKS, an Arabic medical assistant specialized in breast cancer. Always respond in Arabic with empathy and professionalism.**

```plaintext
User: Ø£Ø´Ø¹Ø± Ø¨Ø£Ù„Ù… ÙÙŠ Ø§Ù„Ø«Ø¯ÙŠØŒ Ù‡Ù„ Ù‡Ø°Ø§ Ø·Ø¨ÙŠØ¹ÙŠØŸ
Bot: Ø£ÙÙ‡Ù… Ù‚Ù„Ù‚ÙƒØŒ ÙˆÙ‡Ø°Ø§ Ø´Ø¹ÙˆØ± Ø·Ø¨ÙŠØ¹ÙŠ ØªÙ…Ø§Ù…Ø§Ù‹. Ø¢Ù„Ø§Ù… Ø§Ù„Ø«Ø¯ÙŠ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªØ­Ø¯Ø« Ù„Ø£Ø³Ø¨Ø§Ø¨ Ù…ØªØ¹Ø¯Ø¯Ø© Ù…Ù†Ù‡Ø§...
```

---

## ğŸš€ How to Run This Locally

### 1. ğŸ“¥ Download the Full Project from Google Drive  
ğŸ‘‰ [Click here to download the full project](https://drive.google.com/drive/folders/1znao-Suy9X2N777PSHuG4pW72HN7ht8d?usp=sharing)

### 2. ğŸ—‚ï¸ Extract the Files  
Extract the zip file into a folder on your local machine.

### 3. ğŸ“¦ Install Dependencies

Make sure you have installed:

- Node.js (v18 or higher)
- npm or yarn

Then, open a terminal in the project folder and run:

```bash
npm install
```

### 4. âš™ï¸ Set Up Environment Variables

Create a file called `.env.local` in the root directory and add:

```dotenv
NEXT_PUBLIC_BACKEND_URL=https://your-ngrok-url.ngrok-free.app
```

Replace with the actual URL from running the backend notebook.

### 5. ğŸ§  Start the Backend

Run the notebook `run_final_Back_end.ipynb` (in Colab or Jupyter)  
Copy the `ngrok` URL printed at the end of the notebook and paste it into `.env.local`

### 6. ğŸ§ª Run the Development Server

```bash
npm run dev
```

Then open: [http://localhost:3000](http://localhost:3000)

---

## ğŸ“‚ Project Structure

```
breast-cancer-chatbot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/chat/route.ts
â”‚   â”œâ”€â”€ chat/page.tsx
â”‚   â”œâ”€â”€ about/page.tsx
â”‚   â”œâ”€â”€ contact/page.tsx
â”‚   â”œâ”€â”€ auth/
â”‚   â”œâ”€â”€ layout.tsx
â”‚   â””â”€â”€ page.tsx
â”œâ”€â”€ components/
â”œâ”€â”€ lib/
â”œâ”€â”€ .env.local
â”œâ”€â”€ package.json
â””â”€â”€ next.config.mjs
```

---

## ğŸ¤ Contributions & Future Plans

We welcome contributions from:

- ğŸ§‘â€ğŸ’» Developers (Frontend, Backend, AI)
- ğŸ§‘â€âš•ï¸ Medical professionals (to refine medical content)
- ğŸ”¤ Linguists (to enhance Arabic NLP)
- ğŸ“Š ML Researchers (to push Arabic medical VQA)

### Future Plans

- ğŸ§  Fine-tune Arabic medical LLMs  
- ğŸ—‚ï¸ Build open Arabic breast cancer datasets for VQA  
- ğŸ”Š Add Arabic voice output (TTS) for accessibility  
- ğŸ¥ Extend to other cancers and medical conditions  

---

Â© 2025 BrestaTalks â€” Empowering Arabic healthcare through AI ğŸ’œ